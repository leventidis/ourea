{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "\n",
    "from KDEpy import FFTKDE\n",
    "from scipy import stats\n",
    "from scipy.signal import argrelextrema, argrelmin\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(24, 15)}, font_scale=2)\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE Bandwidth using ISJ Functions\n",
    "\n",
    "def get_outlier_timestamps(df):\n",
    "    '''\n",
    "    Given a dataframe `df` of the processed time series return as a numpy array the timestamps of all detected outliers\n",
    "\n",
    "    If a timestamps corresponds to an outlier from multiple views then the timestamp is repeated for each view \n",
    "    (i.e, there can be repetitions of the same timestamp)\n",
    "    '''\n",
    "    # Get the timestamps of all outliers\n",
    "    outliers_df = df.copy()[df['raw_voting_score'] > 0]\n",
    "    points = []\n",
    "    \n",
    "    # Each vote adds one point (a timestamp with more than 1 votes is added more than once)\n",
    "    for _, row in outliers_df.iterrows():\n",
    "        points += [row[\"unix_time\"]] * row['raw_voting_score']\n",
    "\n",
    "    return np.array(points)\n",
    "\n",
    "def get_local_minima(arr):\n",
    "    '''\n",
    "    Given a list `arr` find its local minima.\n",
    "    If there are flat minima present then only pick the boundaries of the minima flat regions\n",
    "    '''\n",
    "    minima_all = argrelextrema(arr, np.less_equal)[0]\n",
    "\n",
    "    # Refine the minima list to avoid flat minima\n",
    "    minima = []\n",
    "    for min_idx in minima_all:\n",
    "        # Loop over indices that aren't at the boundaries of the input list\n",
    "        if ((min_idx > 0) and (min_idx < (len(arr) - 1))):\n",
    "            if arr[min_idx -1] != arr[min_idx + 1]:\n",
    "                minima.append(min_idx)\n",
    "    \n",
    "    return minima\n",
    "\n",
    "def get_kde_isj_density_df(df):\n",
    "    '''\n",
    "    Run KDE over the timeseries in `df` using Improved Sheather-Jones (ISJ) bandwidth selection\n",
    "\n",
    "    Returns a dataframe with the density\n",
    "    '''\n",
    "    # Get a list of the outlier timestamps\n",
    "    outlier_timestamps = get_outlier_timestamps(df)\n",
    "\n",
    "    # Sample the timestamps for which we estimate the density (use 3X num points of the df)\n",
    "    samples = np.linspace(df['unix_time'].min()-3600,df['unix_time'].max()+3600, num=3*len(df.index))\n",
    "\n",
    "    # Co                                                                                                                                                                                                                                                                                                                                                                    mpute density estimates using 'ISJ' - Improved Sheather Jones\n",
    "    density = FFTKDE(kernel='epa', bw='ISJ').fit(outlier_timestamps).evaluate(samples)\n",
    "\n",
    "    # Create the density_df\n",
    "    density_df = pd.DataFrame({'unix_time': samples, 'density': density})\n",
    "    density_df['timestamp'] = pd.to_datetime(density_df['unix_time'], unit='s')\n",
    "    return density_df\n",
    "\n",
    "def get_isj_clusters_df(density_df, df):\n",
    "    mi = get_local_minima(density_df['density'].values)\n",
    "    clusters_df_ISJ = utils.clustering.get_clusters_df(\n",
    "        samples=density_df['unix_time'].values, density_dist=density_df['density'].values, minima_idx_list=mi,\n",
    "        points=get_outlier_timestamps(df)\n",
    "    )\n",
    "    clusters_df_ISJ = clusters_df_ISJ.sort_values(by='area', ascending=False)\n",
    "    return clusters_df_ISJ\n",
    "\n",
    "def get_timeseries_and_density_figure(df, density, clusters, k):\n",
    "    df = df.sort_values(by='timestamp')\n",
    "\n",
    "    k_clusters = clusters.sort_values(by='area', ascending=False).head(k).reset_index()\n",
    "    k_clusters\n",
    "\n",
    "    # Plot the Figure\n",
    "    fig, axs = plt.subplots(2, sharex=True)\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "\n",
    "    axs[0].plot(df['unix_time'], df['measure'])\n",
    "    axs[0].scatter(df[df['is_outlier']==1]['unix_time'].values, df[df['is_outlier']==1]['measure'].values, s=90, c='red', zorder=10, label='True Injected Outliers')\n",
    "    axs[0].scatter(df[df['raw_voting_score']>0]['unix_time'].values, df[df['raw_voting_score']>0]['measure'].values, s=30, c='green', zorder=10, label='Detected Outliers')\n",
    "    axs[0].set_ylabel('Measure');axs[0].legend()\n",
    "\n",
    "    # Plot the alert regions\n",
    "    for _, alert in k_clusters.iterrows():\n",
    "        axs[0].add_patch(patches.Rectangle((alert['start'], -1.5), width=alert['end']-alert['start'], height=3, linewidth=0, color='yellow', zorder=10, alpha=0.40))\n",
    "\n",
    "    axs[1].plot(density['unix_time'], density['density'])\n",
    "    axs[1].set_ylabel('Density');axs[1].set_xlabel('Unix Time')\n",
    "    for idx, alert in k_clusters.iterrows():\n",
    "        axs[1].add_patch(patches.Rectangle((alert['start'], 0), width=alert['end']-alert['start'], height=density['density'].max(), linewidth=0, color='yellow', zorder=10, alpha=0.40))\n",
    "        x_loc = alert['start'] + (alert['end'] - alert['start'])/2\n",
    "        axs[1].text(x=x_loc, y=density['density'].max(), s=str(idx+1), fontsize=12, color='red', horizontalalignment='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Related Functions\n",
    "\n",
    "def get_real_and_predicted_ranges(regions_df, clusters_df, cluster_points_bounds=False):\n",
    "    '''\n",
    "    Given the `regions_df` and the `clusters_df` extract the real and predicted anomalous regions\n",
    "    \n",
    "    Notice that the predicted anomalous regions are set to be equal to the number of the true regions\n",
    "    and the order they are picked is specified by the order of the rows in the `clusters_df`\n",
    "    '''\n",
    "    # Extract the real anomaly ranges and the predicted anomaly ranges\n",
    "    real_ranges = []\n",
    "    predicted_ranges = []\n",
    "    for _, row in regions_df.iterrows():\n",
    "        real_ranges.append([row['unix_start'], row['unix_end']])\n",
    "    for _, row in clusters_df.iterrows():\n",
    "        if cluster_points_bounds:\n",
    "            predicted_ranges.append([row['point_start'], row['point_end']])\n",
    "        else:\n",
    "            predicted_ranges.append([row['start'], row['end']])\n",
    "    predicted_ranges = predicted_ranges[:len(real_ranges)]\n",
    "\n",
    "    return real_ranges, predicted_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_df_over_dir(dir_paths, cluster_points_bounds=False):\n",
    "    precision_list = [];recall_list = []\n",
    "    precision_isj_list =[];recall_isj_list = []\n",
    "    precision_isj_tight_list=[];recall_isj_tight_list=[]\n",
    "\n",
    "    for path in tqdm(dir_paths):\n",
    "        regions_df = pd.read_pickle(path + 'regions_df.pickle')\n",
    "        \n",
    "        df = pd.read_pickle(path + 'df.pickle').sort_values(by='unix_time')\n",
    "        clusters_df = pd.read_pickle(path + 'clusters_df.pickle').sort_values(by='area', ascending=False)\n",
    "\n",
    "        # Add unix time to the regions_df\n",
    "        regions_df['unix_start'] = df.loc[regions_df['start']]['unix_time'].values\n",
    "        regions_df['unix_end'] = df.loc[regions_df['end']]['unix_time'].values\n",
    "\n",
    "        # Compute the range-based precision and recall\n",
    "        real_ranges, predicted_ranges = get_real_and_predicted_ranges(regions_df, clusters_df, cluster_points_bounds=cluster_points_bounds)\n",
    "        recall = utils.metrics.range_based_recall(real_ranges=real_ranges, predicted_ranges=predicted_ranges, alpha=1, delta_mode='flat')\n",
    "        precision = utils.metrics.range_based_precision(real_ranges=real_ranges, predicted_ranges=predicted_ranges, delta_mode='flat')\n",
    "        precision_list.append(precision);recall_list.append(recall)\n",
    "\n",
    "        # Get clusters using bandwidth from ISJ \n",
    "        density_df_ISJ = get_kde_isj_density_df(df)\n",
    "        clusters_df_ISJ = get_isj_clusters_df(density_df_ISJ, df)\n",
    "\n",
    "        # Save the density_df and cluster_df for ISJ in the directory\n",
    "        density_df_ISJ.to_pickle(path+'density_ISJ_df.pickle')\n",
    "        clusters_df_ISJ.to_pickle(path+'clusters_ISJ_df.pickle')\n",
    "\n",
    "        # Save the timeseries_density plot using ISJ bandwidth\n",
    "        fig = get_timeseries_and_density_figure(df, density_df_ISJ, clusters_df_ISJ, k=len(regions_df.index))\n",
    "        fig.savefig(path+'figures/timeseries_density_ISJ_plot.svg')  \n",
    "\n",
    "        # Compute the range-based precision and recall with ISJ bandwidth\n",
    "        real_ranges, predicted_ranges = get_real_and_predicted_ranges(regions_df, clusters_df_ISJ, cluster_points_bounds=True)\n",
    "        recall_isj = utils.metrics.range_based_recall(real_ranges=real_ranges, predicted_ranges=predicted_ranges, alpha=1, delta_mode='flat')\n",
    "        precision_isj = utils.metrics.range_based_precision(real_ranges=real_ranges, predicted_ranges=predicted_ranges, delta_mode='flat')\n",
    "        precision_isj_list.append(precision_isj);recall_isj_list.append(recall_isj)\n",
    "\n",
    "        # Compute range-based precision and recall with ISJ bandwidth but tight\n",
    "        real_ranges, predicted_ranges = get_real_and_predicted_ranges(regions_df, clusters_df_ISJ, cluster_points_bounds=cluster_points_bounds)\n",
    "        recall_tight_isj = utils.metrics.range_based_recall(real_ranges=real_ranges, predicted_ranges=predicted_ranges, alpha=1, delta_mode='flat')\n",
    "        precision_tight_isj = utils.metrics.range_based_precision(real_ranges=real_ranges, predicted_ranges=predicted_ranges, delta_mode='flat')\n",
    "        precision_isj_tight_list.append(precision_tight_isj);recall_isj_tight_list.append(recall_tight_isj)\n",
    "    \n",
    "    evaluation_dict = {\n",
    "        'precision': precision_list, 'recall': recall_list, 'precision_isj': precision_isj_list, 'recall_isj': recall_isj_list, 'precision_isj_tight':  precision_isj_tight_list, 'recall_isj_tight': recall_isj_tight_list,\n",
    "        'seed': list(range(1, len(precision_list) + 1))\n",
    "    }\n",
    "    evaluation_df = pd.DataFrame.from_dict(evaluation_dict)\n",
    "    evaluation_df['f1_score'] = (2 * evaluation_df['precision'].to_numpy() * evaluation_df['recall'].to_numpy()) / (evaluation_df['precision'].to_numpy() + evaluation_df['recall'].to_numpy())\n",
    "    evaluation_df['f1_score_isj'] = (2 * evaluation_df['precision_isj'].to_numpy() * evaluation_df['recall_isj'].to_numpy()) / (evaluation_df['precision_isj'].to_numpy() + evaluation_df['recall_isj'].to_numpy())\n",
    "    evaluation_df['f1_score_isj_tight'] = (2 * evaluation_df['precision_isj_tight'].to_numpy() * evaluation_df['precision_isj_tight'].to_numpy()) / (evaluation_df['precision_isj_tight'].to_numpy() + evaluation_df['precision_isj_tight'].to_numpy())\n",
    "\n",
    "    return evaluation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meanshift5 Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISJ Evaluation:\n",
      "Mean/SDEV: Range-Based Precision: 0.7875461349935235 0.12432242062212612\n",
      "Mean/SDEV Range-Based Recall: 0.6274999999999998 0.12640623146639315\n",
      "Mean/SDEV F1-Score: 0.6901761827115953 0.10377302098730616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dir_paths = sorted(glob(\"../synthetic_data/mdi_synthetic_data/meanshift5/*/\"))\n",
    "evaluation_df = get_eval_df_over_dir(dir_paths)\n",
    "\n",
    "print(\"ISJ Evaluation:\")\n",
    "print(\"Mean/SDEV: Range-Based Precision:\", evaluation_df['precision_isj'].mean(), evaluation_df['precision_isj'].std())\n",
    "print(\"Mean/SDEV Range-Based Recall:\", evaluation_df['recall_isj'].mean(), evaluation_df['recall_isj'].std())\n",
    "print(\"Mean/SDEV F1-Score:\", evaluation_df['f1_score_isj'].mean(), evaluation_df['f1_score_isj'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision               0.175090\n",
       "recall                  0.965500\n",
       "precision_isj           0.787546\n",
       "recall_isj              0.627500\n",
       "precision_isj_tight     0.560800\n",
       "recall_isj_tight        0.639500\n",
       "seed                   50.500000\n",
       "f1_score                0.294958\n",
       "f1_score_isj            0.690176\n",
       "f1_score_isj_tight      0.560800\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meanshift5_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:22<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISJ Evaluation:\n",
      "Mean/SDEV: Range-Based Precision: 0.5283452644553105 0.23852645946288176\n",
      "Mean/SDEV Range-Based Recall: 0.4777777777777778 0.17514166601526654\n",
      "Mean/SDEV F1-Score: 0.49813067822704593 0.18229170655895502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "<ipython-input-45-6dc4e2729d19>:52: RuntimeWarning: invalid value encountered in true_divide\n",
      "  evaluation_df['f1_score_isj'] = (2 * evaluation_df['precision_isj'].to_numpy() * evaluation_df['recall_isj'].to_numpy()) / (evaluation_df['precision_isj'].to_numpy() + evaluation_df['recall_isj'].to_numpy())\n",
      "<ipython-input-45-6dc4e2729d19>:53: RuntimeWarning: invalid value encountered in true_divide\n",
      "  evaluation_df['f1_score_isj_tight'] = (2 * evaluation_df['precision_isj_tight'].to_numpy() * evaluation_df['precision_isj_tight'].to_numpy()) / (evaluation_df['precision_isj_tight'].to_numpy() + evaluation_df['precision_isj_tight'].to_numpy())\n"
     ]
    }
   ],
   "source": [
    "dir_paths = sorted(glob(\"../synthetic_data/mdi_synthetic_data/meanshift5_hard/*/\"))\n",
    "evaluation_df = get_eval_df_over_dir(dir_paths)\n",
    "\n",
    "print(\"ISJ Evaluation:\")\n",
    "print(\"Mean/SDEV: Range-Based Precision:\", evaluation_df['precision_isj'].mean(), evaluation_df['precision_isj'].std())\n",
    "print(\"Mean/SDEV Range-Based Recall:\", evaluation_df['recall_isj'].mean(), evaluation_df['recall_isj'].std())\n",
    "print(\"Mean/SDEV F1-Score:\", evaluation_df['f1_score_isj'].mean(), evaluation_df['f1_score_isj'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63c1931a49d52633ba1ecf80b98b93c2e12d4e1a2fe3adefed6c32e16e3d9686"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
