{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(24, 15)}, font_scale=2)\n",
    "\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from argparse import Namespace\n",
    "from KDEpy import FFTKDE\n",
    "from scipy import stats\n",
    "from scipy.signal import argrelextrema, argrelmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE Bandwidth using ISJ Functions\n",
    "\n",
    "def get_outlier_timestamps(df):\n",
    "    '''\n",
    "    Given a dataframe `df` of the processed time series return as a numpy array the timestamps of all detected outliers\n",
    "\n",
    "    If a timestamps corresponds to an outlier from multiple views then the timestamp is repeated for each view \n",
    "    (i.e, there can be repetitions of the same timestamp)\n",
    "    '''\n",
    "    # Get the timestamps of all outliers\n",
    "    outliers_df = df.copy()[df['raw_voting_score'] > 0]\n",
    "    points = []\n",
    "    \n",
    "    # Each vote adds one point (a timestamp with more than 1 votes is added more than once)\n",
    "    for _, row in outliers_df.iterrows():\n",
    "        points += [row[\"unix_time\"]] * row['raw_voting_score']\n",
    "\n",
    "    return np.array(points)\n",
    "\n",
    "def get_local_minima(arr):\n",
    "    '''\n",
    "    Given a list `arr` find its local minima.\n",
    "    If there are flat minima present then only pick the boundaries of the minima flat regions\n",
    "    '''\n",
    "    minima_all = argrelextrema(arr, np.less_equal)[0]\n",
    "\n",
    "    # Refine the minima list to avoid flat minima\n",
    "    minima = []\n",
    "    for min_idx in minima_all:\n",
    "        # Loop over indices that aren't at the boundaries of the input list\n",
    "        if ((min_idx > 0) and (min_idx < (len(arr) - 1))):\n",
    "            if arr[min_idx -1] != arr[min_idx + 1]:\n",
    "                minima.append(min_idx)\n",
    "    \n",
    "    return minima\n",
    "\n",
    "def get_kde_isj_density_df(df):\n",
    "    '''\n",
    "    Run KDE over the timeseries in `df` using Improved Sheather-Jones (ISJ) bandwidth selection\n",
    "\n",
    "    Returns a dataframe with the density\n",
    "    '''\n",
    "    # Get a list of the outlier timestamps\n",
    "    outlier_timestamps = get_outlier_timestamps(df)\n",
    "\n",
    "    # Sample the timestamps for which we estimate the density (use 3X num points of the df)\n",
    "    samples = np.linspace(df['unix_time'].min(),df['unix_time'].max(), num=3*len(df.index))\n",
    "\n",
    "    # Co                                                                                                                                                                                                                                                                                                                                                                    mpute density estimates using 'ISJ' - Improved Sheather Jones\n",
    "    density = FFTKDE(kernel='epa', bw='ISJ').fit(outlier_timestamps).evaluate(samples)\n",
    "\n",
    "    # Create the density_df\n",
    "    density_df = pd.DataFrame({'unix_time': samples, 'density': density})\n",
    "    density_df['timestamp'] = pd.to_datetime(density_df['unix_time'], unit='s')\n",
    "    return density_df\n",
    "\n",
    "def get_isj_clusters_df(density_df, df):\n",
    "    mi = get_local_minima(density_df['density'].values)\n",
    "    clusters_df_ISJ = utils.clustering.get_clusters_df(\n",
    "        samples=density_df['unix_time'].values, density_dist=density_df['density'].values, minima_idx_list=mi,\n",
    "        points=get_outlier_timestamps(df)\n",
    "    )\n",
    "    clusters_df_ISJ = clusters_df_ISJ.sort_values(by='area', ascending=False)\n",
    "    return clusters_df_ISJ\n",
    "\n",
    "def get_timeseries_and_density_figure(df, density, clusters, k):\n",
    "    df = df.sort_values(by='timestamp')\n",
    "\n",
    "    k_clusters = clusters.sort_values(by='area', ascending=False).head(k).reset_index()\n",
    "    k_clusters\n",
    "\n",
    "    # Plot the Figure\n",
    "    fig, axs = plt.subplots(2, sharex=True)\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "\n",
    "    axs[0].plot(df['unix_time'], df['measure'])\n",
    "    axs[0].scatter(df[df['is_outlier']==1]['unix_time'].values, df[df['is_outlier']==1]['measure'].values, s=90, c='red', zorder=10, label='True Injected Outliers')\n",
    "    axs[0].scatter(df[df['raw_voting_score']>0]['unix_time'].values, df[df['raw_voting_score']>0]['measure'].values, s=30, c='green', zorder=10, label='Detected Outliers')\n",
    "    axs[0].set_ylabel('Measure');axs[0].legend()\n",
    "\n",
    "    # Plot the alert regions\n",
    "    for _, alert in k_clusters.iterrows():\n",
    "        axs[0].add_patch(patches.Rectangle((alert['start'], -1.5), width=alert['end']-alert['start'], height=3, linewidth=0, color='yellow', zorder=10, alpha=0.40))\n",
    "\n",
    "    axs[1].plot(density['unix_time'], density['density'])\n",
    "    axs[1].set_ylabel('Density');axs[1].set_xlabel('Unix Time')\n",
    "    for idx, alert in k_clusters.iterrows():\n",
    "        axs[1].add_patch(patches.Rectangle((alert['start'], 0), width=alert['end']-alert['start'], height=density['density'].max(), linewidth=0, color='yellow', zorder=10, alpha=0.40))\n",
    "        x_loc = alert['start'] + (alert['end'] - alert['start'])/2\n",
    "        axs[1].text(x=x_loc, y=density['density'].max(), s=str(idx+1), fontsize=12, color='red', horizontalalignment='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Runtime of different components in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(window_size='6H', aggregation_model='aggregate_prophet_model', confidence_interval_width=0.98, num_points_per_window=6, point_frequency='1H', kernel='gaussian', bandwidth=86400)\n",
    "\n",
    "df_path = '../streaming_data/all_outlier_types/df_full.pickle'\n",
    "df_full = pd.read_pickle(df_path)\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "cur_df = df_full.copy()\n",
    "\n",
    "# Fit model on raw data and identify outliers in the raw outliers\n",
    "start = timer()\n",
    "raw_model, forecast = utils.outlier_detection.raw_data_fit(cur_df, confidence_interval_width=args.confidence_interval_width)\n",
    "cur_df = utils.outlier_detection.update_df_with_raw_model_fit(df=cur_df, forecast=forecast)\n",
    "end = timer()\n",
    "prophet_raw_fit_time = end-start\n",
    "\n",
    "# Fit model over aggregate views and identify aggregate level outliers\n",
    "start = timer()\n",
    "df_agg = utils.aggregation.get_aggregate_df(df=cur_df, args=args)\n",
    "\n",
    "# Identify outliers across all views (raw + aggregation) and perform voting \n",
    "# (assign each timestamp to count of views that marked it as an outlier)\n",
    "cur_df = cur_df.copy()[:math.floor(len(cur_df.index) / len(args.window_size)) * len(df_agg.index)]\n",
    "cur_df = utils.voting.add_voting_to_df(df=cur_df, df_agg=df_agg, period=args.num_points_per_window, freq=args.point_frequency)\n",
    "end = timer()\n",
    "prophet_agg_fit_time = end-start\n",
    "\n",
    "# # TODO: Only compute KDE in the frozen time range (i.e., time range where new data does not have an impact to kde)\n",
    "# start = timer()\n",
    "# cur_df, density_df, clusters_df = utils.clustering.perform_clustering(df=cur_df, kernel=args.kernel, bandwidth=args.bandwidth)\n",
    "# end = timer()\n",
    "# kde_time = end-start\n",
    "\n",
    "print(\"Prophet Raw Fit Time Elapsed:\", prophet_raw_fit_time)\n",
    "print(\"Prophet Aggregate Fit Time Elapsed:\", prophet_agg_fit_time)\n",
    "# print('Clustering Time Elapsed:', kde_time)\n",
    "\n",
    "# clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "density_df_ISJ = get_kde_isj_density_df(cur_df)\n",
    "clusters_df_ISJ = get_isj_clusters_df(density_df_ISJ, cur_df)\n",
    "end = timer()\n",
    "kde_isj_time = end-start\n",
    "print('Clustering using ISJ Bandwidth Selection Time Elapsed', kde_isj_time)\n",
    "\n",
    "clusters_df_ISJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Sklearn vs. KDEpy runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from KDEpy import FFTKDE\n",
    "\n",
    "# Get the list of outliers and the timestamps for which to compute KDE\n",
    "outlier_pts = get_outlier_timestamps(cur_df)\n",
    "samples = np.linspace(cur_df['unix_time'].min(),cur_df['unix_time'].max(), num=3*len(cur_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "start = timer()\n",
    "kde = KernelDensity(kernel='epanechnikov', bandwidth=86400).fit(np.array(outlier_pts).reshape(-1,1))\n",
    "density_sklearn = np.exp(kde.score_samples(samples.reshape(-1,1)))\n",
    "sklearn_time = timer() - start\n",
    "\n",
    "# KDEpy\n",
    "start = timer()\n",
    "density_kdepy = FFTKDE(kernel='epa', bw=86400).fit(outlier_pts).evaluate(samples)\n",
    "kdepy_time = timer() - start\n",
    "\n",
    "print(\"Sklearn Time:\", sklearn_time)\n",
    "print(\"KDEpy Time:\", kdepy_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KDEpy import FFTKDE\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Generate a distribution and some data\n",
    "dist = norm(loc=0, scale=1)\n",
    "data = dist.rvs(2**8) # Generate 2**8 points\n",
    "model = FFTKDE(kernel='gaussian', bw='ISJ').fit(data)\n",
    "x, y = model.evaluate()\n",
    "\n",
    "\n",
    "# plt.plot(x, y)\n",
    "print(model.bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(density_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(density_kdepy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "area = integrate.simps(x = samples, y=density_kdepy)\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../streaming_data/all_outlier_types/future_prediction_isj/outputs/size_10080/df.pickle')\n",
    "density_df = pd.read_pickle('../streaming_data/all_outlier_types/future_prediction_isj/outputs/size_10080/density_df.pickle')\n",
    "clusters_df = pd.read_pickle('../streaming_data/all_outlier_types/future_prediction_isj/outputs/size_10080/clusters_df.pickle')\n",
    "clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_timeseries_and_density_figure(df, density_df, clusters_df, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime per component across iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_bandwidth_path = '../streaming_data/all_outlier_types/fixed_bandwidth/outputs/'\n",
    "ISJ_bandwidth_path = '../streaming_data/all_outlier_types/ISJ/outputs/'\n",
    "future_prediction_path = '../streaming_data/all_outlier_types/future_prediction_isj/outputs/'\n",
    "\n",
    "size_start = 2016\n",
    "size_end = 10080\n",
    "step_size = 6\n",
    "\n",
    "runtime_dict = {\"size\": [], \"iteration\": [], \"prophet\": [], \"prophet_agg\": [], 'kde_fixed': [], 'kde_isj': [], 'isj_bandwidth': []}\n",
    "future_pred_runtime_dict = {\"size\": [], \"iteration\": [], \"prophet\": [], \"prophet_agg\": [], 'kde_isj': [], 'isj_bandwidth': []}\n",
    "\n",
    "for size in range(size_start, size_end, step_size):\n",
    "    \n",
    "    with open(fixed_bandwidth_path+'size_'+str(size)+'/runtime.json') as f:\n",
    "        fixed_runtime = json.load(f)\n",
    "\n",
    "    with open(ISJ_bandwidth_path+'size_'+str(size)+'/stats.json') as f:\n",
    "        isj_runtime = json.load(f)\n",
    "\n",
    "    with open(future_prediction_path+'size_'+str(size)+'/stats.json') as f:\n",
    "        future_prediction_runtime = json.load(f)\n",
    "\n",
    "    runtime_dict['size'].append(size)\n",
    "    runtime_dict['iteration'].append((size - size_start)/step_size + 1)\n",
    "    runtime_dict['prophet'].append((fixed_runtime['raw_fit_time'] + isj_runtime['raw_fit_time'])/2)\n",
    "    runtime_dict['prophet_agg'].append((fixed_runtime['agg_fit_time'] + isj_runtime['agg_fit_time'])/2)\n",
    "    runtime_dict['kde_fixed'].append(fixed_runtime['kde_time'])\n",
    "    runtime_dict['kde_isj'].append(isj_runtime['kde_time'])\n",
    "    runtime_dict['isj_bandwidth'].append(isj_runtime['bandwidth'])\n",
    "\n",
    "    future_pred_runtime_dict['size'].append(size)\n",
    "    future_pred_runtime_dict['iteration'].append((size - size_start)/step_size + 1)\n",
    "    future_pred_runtime_dict['prophet'].append(future_prediction_runtime['raw_fit_time'])\n",
    "    future_pred_runtime_dict['prophet_agg'].append(future_prediction_runtime['agg_fit_time'])\n",
    "    future_pred_runtime_dict['kde_isj'].append(future_prediction_runtime['kde_time'])\n",
    "    future_pred_runtime_dict['isj_bandwidth'].append(future_prediction_runtime['bandwidth'])\n",
    "\n",
    "df_runtime = pd.DataFrame.from_dict(runtime_dict)\n",
    "df_runtime['total_runtime_fixed'] = df_runtime['prophet'] + df_runtime['prophet_agg'] + df_runtime['kde_fixed']\n",
    "df_runtime['total_runtime_isj'] = df_runtime['prophet'] + df_runtime['prophet_agg'] + df_runtime['kde_isj']\n",
    "\n",
    "df_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fiting_time = df_runtime['prophet'].sum() + df_runtime['prophet_agg'].sum()\n",
    "kde_time = df_runtime['kde_isj'].sum()\n",
    "print(\"Total model fitting time:\", model_fiting_time)\n",
    "print(\"Total kde time:\", kde_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtime_future_pred = pd.DataFrame.from_dict(future_pred_runtime_dict)\n",
    "df_runtime_future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_runtime['iteration'], df_runtime['prophet'], label='Prophet Raw View Fit')\n",
    "plt.plot(df_runtime['iteration'], df_runtime['prophet_agg'], label='Prophet Aggregate Views Fit')\n",
    "plt.plot(df_runtime['iteration'], df_runtime['kde_fixed'], label='KDE Fixed Bandwidth')\n",
    "plt.plot(df_runtime['iteration'], df_runtime['kde_isj'], label='KDE ISJ Bandwidth')\n",
    "\n",
    "plt.ylabel('Time (seconds)');plt.xlabel('Iteration');plt.legend();plt.title('Total Runtime per component');plt.tight_layout()\n",
    "plt.savefig('../figures/benchmarking/runtime_per_component.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_runtime['iteration'], df_runtime['prophet']/df_runtime['total_runtime_fixed'], label='Prophet Raw View Fit')\n",
    "plt.plot(df_runtime['iteration'], df_runtime['prophet_agg']/df_runtime['total_runtime_fixed'], label='Prophet Aggregate Views Fit')\n",
    "plt.plot(df_runtime['iteration'], df_runtime['kde_fixed']/df_runtime['total_runtime_fixed'], label='KDE Fixed Bandwidth')\n",
    "plt.title('% of Runtime per component (KDE Fixed Bandwidth)');plt.ylabel('% of total runtime');plt.xlabel('Iteration');plt.legend();plt.tight_layout()\n",
    "plt.savefig('../figures/benchmarking/percent_runtime_per_component_fixed_bandwidth.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_runtime['iteration'], df_runtime['prophet']/df_runtime['total_runtime_isj'], label='Prophet Raw View Fit')\n",
    "plt.plot(df_runtime['iteration'], df_runtime['prophet_agg']/df_runtime['total_runtime_isj'], label='Prophet Aggregate Views Fit')\n",
    "plt.plot(df_runtime['iteration'], df_runtime['kde_isj']/df_runtime['total_runtime_isj'], label='KDE ISJ Bandwidth')\n",
    "plt.title('% of Runtime per component (KDE ISJ Bandwidth)');plt.ylabel('% of total runtime');plt.xlabel('Iteration');plt.legend();plt.tight_layout()\n",
    "plt.savefig('../figures/benchmarking/percent_runtime_per_component_ISJ_bandwidth.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_runtime['iteration'], df_runtime['isj_bandwidth'])\n",
    "plt.title('Selected ISJ Bandwidth across iterations');plt.ylabel('ISJ Bandwidth (seconds)');plt.xlabel('Iteration');plt.tight_layout()\n",
    "plt.savefig('../figures/benchmarking/isj_bandwidth_vs_iterations.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_runtime_future_pred['iteration'], df_runtime_future_pred['prophet'], label='Prophet Raw View Fit')\n",
    "plt.plot(df_runtime_future_pred['iteration'], df_runtime_future_pred['prophet_agg'], label='Prophet Aggregate Views Fit')\n",
    "plt.plot(df_runtime_future_pred['iteration'], df_runtime_future_pred['kde_isj'], label='KDE ISJ Bandwidth')\n",
    "\n",
    "plt.ylabel('Time (seconds)');plt.xlabel('Iteration');plt.legend();plt.title('Total Runtime per component (With 1 week ahead prediction)');plt.tight_layout()\n",
    "plt.savefig('../figures/benchmarking/runtime_per_component_with_future_prediction.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fiting_time = df_runtime_future_pred['prophet'].sum() + df_runtime_future_pred['prophet_agg'].sum()\n",
    "kde_time = df_runtime_future_pred['kde_isj'].sum()\n",
    "print(\"Total model fitting time:\", model_fiting_time)\n",
    "print(\"Total kde time:\", kde_time)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63c1931a49d52633ba1ecf80b98b93c2e12d4e1a2fe3adefed6c32e16e3d9686"
  },
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('venv': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
